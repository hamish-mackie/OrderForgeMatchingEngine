// File to keep track of benchmarking results

// This result is the first run, I've used a release build and turned logging off, nothing has really been optimised.
// The results were very bad with logging turned on.
// We can also see that as we hold more data in our order book, the process time gets considerably worse.

Time to insert and remove 50,000 orders with market orders crossing the book: 0.219833 seconds (227445.67 orders/second)
Time to insert and remove 100,000 orders with market orders crossing the book: 0.876737 seconds (114059.30 orders/second)
Time to insert and remove 500,000 orders with market orders crossing the book: 21.846674 seconds (22886.78 orders/second)

// I noticed that the thing that was taking the time was removing orders, and iterating the vector.
// I've changed the data structure of the order book level to a vector<orderid, Order*> and got significant speed ups.
// Despite having to copy and allocate a new pointer on the heap, its much faster to iterate the vector of smaller objects,
// When the vector needs to reallocate, it also won't have to copy as much.
// This gives me an idea, Since we need to allocate each time anyway, We may as well use a map.

Time to insert and remove 50,000 orders with market orders crossing the book: 0.094536 seconds (528900.27 orders/second)
Time to insert and remove 100,000 orders with market orders crossing the book: 0.331053 seconds (302066.67 orders/second)
Time to insert and remove 500,000 orders with market orders crossing the book: 7.511813 seconds (66561.83 orders/second)

// Getting faster...
// Changed the book level data structure into a hashed linked list...

Time to insert and remove 50,000 orders with market orders crossing the book: 0.034224 seconds (1460975.06 orders/second)
Time to insert and remove 100,000 orders with market orders crossing the book: 0.101978 seconds (980601.95 orders/second)
Time to insert and remove 500,000 orders with market orders crossing the book: 0.920041 seconds (543454.25 orders/second)

// Bit of an interesting benchmark here, I've swapped computers with a 3950x and 32gb of ram and it seems to have doubled.
Time to insert and remove 50,000 orders with market orders crossing the book: 0.020098 seconds (2487781.63 orders/second)
Time to insert and remove 100,000 orders with market orders crossing the book: 0.049794 seconds (2008256.30 orders/second)
Time to insert and remove 500,000 orders with market orders crossing the book: 0.564575 seconds (885621.60 orders/second)

// Implemented a custom allocator, and it seems the performance is not as good...?
Time to insert and remove 50,000 orders with market orders crossing the book: 0.090644 seconds (551608.05 orders/second)
Time to insert and remove 100,000 orders with market orders crossing the book: 0.210105 seconds (475952.17 orders/second)
Time to insert and remove 500,000 orders with market orders crossing the book: 1.221789 seconds (409236.09 orders/second)

// Fixed a small issue and the allocator is similar, maybe slightly better than the std::allocator, use pmr vectors in orderbook
Time to insert and remove 50,000 orders with market orders crossing the book: 0.018510 seconds (2701238.49 orders/second)
Time to insert and remove 100,000 orders with market orders crossing the book: 0.043155 seconds (2317247.39 orders/second)
Time to insert and remove 500,000 orders with market orders crossing the book: 0.484181 seconds (1032671.51 orders/second)